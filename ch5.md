# Ch.5 íŠ¸ë¦¬ ì•Œê³ ë¦¬ì¦˜
## 1. ê²°ì • íŠ¸ë¦¬
![plot_tree](image-4.png)
```python
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
plt.figure(figsize=(10, 7))
plot_tree(dt)
plt.show()
```
- `plot_tree()` : ê²°ì •íŠ¸ë¦¬ë¥¼ íŠ¸ë¦¬ ê·¸ë¦¼ìœ¼ë¡œ ì¶œë ¥
ë„ˆë¬´ ë³µì¡!! â¡ï¸ **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìˆ˜ì •**

![max_depth](image-5.png)
```python
plot_tree(dt, max_depth=1, filled=True, feature_names=['í–‰1', 'í–‰2', 'í–‰3'])
plt.show()
```
- `label='all'/'root'/'none'`(ê¸°ë³¸ê°’ì€ all) : í‘œì‹œí•  í…ìŠ¤íŠ¸ ì¢…ë¥˜
  - í…ŒìŠ¤íŠ¸ ì¡°ê±´ ex. sugar <= -0.239
  - gini ì§€ë‹ˆë¶ˆìˆœë„ 
  - samples ì´ ìƒ˜í”Œ ìˆ˜
  - value í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ 
- `filled=True` : ë…¸ë“œì˜ ë°°ê²½ìƒ‰ ì—¬ë¶€; ì–´ë–¤ í´ë˜ìŠ¤ì˜ ë¹„ìœ¨ì´ ë†’ì•„ì§€ë©´ ìƒ‰ì´ ì§„í•´ì§

â“ **gini ì§€ë‹ˆ ë¶ˆìˆœë„**
![gini](image-6.png)
- gini = 0.5 : ë…¸ë“œì˜ ë‘ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ì •í™•íˆ 1/2ì”© => ìµœì•…!
- gini = 0 : ë…¸ë“œì— í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë§Œ ìˆëŠ”ê²ƒ(ìˆœìˆ˜ë…¸ë“œ)
1. ì´ì§„ë¶„ë¥˜ì¸ ê²½ìš°
0(ìˆœìˆ˜ë…¸ë“œ) <= gini(G) <= 0.5 (ë°˜ë°˜)
2. ë‹¤ì¤‘í´ë˜ìŠ¤ì¸ ê²½ìš°
0 <= gini(G) < 1 (0.5ë³´ë‹¤ ì»¤ì§ˆ ìˆ˜ ìˆìŒ)

```text
ê²°ì •íŠ¸ë¦¬ê°€ ë…¸ë“œë¥¼ ë‚˜ëˆ„ëŠ” ë°©ë²•
ğŸ’¡ ë¶€ëª¨ì™€ ìì‹ ë…¸ë“œ ì‚¬ì´ì˜ ë¶ˆìˆœë„ ì°¨ì´(ì •ë³´ ì´ë“)ì´ ìµœëŒ€ê°€ ë˜ë„ë¡
>> ë¶ˆìˆœë„ì— ë”°ë¼ ë‚˜ëˆ„ê¸° ë•Œë¬¸ì— â€¼ï¸í‘œì¤€í™” ì „ì²˜ë¦¬ ë¶ˆí•„ìš”â€¼ï¸
```

â“ **entropy ì—”íŠ¸ë¡œí”¼**
![entropy](image-7.png)
```
gini vs entropy
> ì†ë„ì™€ ì´ë¡ ì  í•´ì„ì˜ ì°¨ì´ê°€ ìˆìœ¼ë‚˜, ê²°ì • íŠ¸ë¦¬ì—ì„œ í° ì°¨ì´ ì—†ìŒ
> DecisionTreeClassifierì˜ default ëŠ” gini
```

**feature_importances**
```python
print(dt.feature_importances_)
```
- íŠ¹ì„± ì¤‘ìš”ë„ì˜ íš¨ê³¼?ë¥¼ ì˜ ëª» ëŠê¼ˆëŠ”ë° í™•ì‹¤íˆ ê²°ì •íŠ¸ë¦¬ì—ì„œëŠ” í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ”ë° ì–´ë–¤ íŠ¹ì„±ì´ ì˜í–¥ì„ ë§ì´ ë¯¸ì³¤ëŠ”ì§€ ë³´ê³  í•´ì„í•  ìˆ˜ ìˆê² êµ¬ë‚˜..~!

## 2. êµì°¨ ê²€ì¦ê³¼ ê·¸ë¦¬ë“œ ì„œì¹˜
```python
from sklearn.model_selection import GridSearchCV
params = {'min_impurity_decrease' : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)
dt = gs.best_estimator_
```
- GridSearch ë¥¼ ì´ìš©í•˜ë©´ í•˜ì´í¼íŒŒë¼ë¯¸í„° & ëª¨ë¸ íŒŒë¼ë¯¸í„° ìµœì ê°’ ì°¾ê¸° í•œ ë²ˆì— ê°€ëŠ¥
- `min_impurity_decrease` : ë…¸ë“œë¥¼ ë¶„í• í•˜ê¸° ìœ„í•œ ë¶ˆìˆœë„ ê°ì†Œ ìµœì†ŒëŸ‰ 

â¡ï¸ ë” ë³µì¡í•˜ê²Œ 
```python
params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001), 'max_depth': range(5, 20, 1), 'min_samples_split': range(2, 100, 10)}
```
- `range(ìˆ«ì1, ìˆ«ì2, ìˆ«ì3)` : ìˆ«ì1ì—ì„œ ì‹œì‘í•´ì„œ ìˆ«ì2ê°€ ë  ë•Œê¹Œì§€ ìˆ«ì3ì”© ì¦ê°€í•˜ë©´ì„œ ë§¤ê°œë³€ìˆ˜ ì¡°ì • 

â¡ï¸ ë§¤ê°œë³€ìˆ˜ ê°’ ë²”ìœ„ë‚˜ ê°„ê²© ì •í•˜ê¸° ì–´ë ¤ìš¸ ë•Œ / ë„ˆë¬´ ë§ì€ ë§¤ê°œë³€ìˆ˜ ì¡°ê±´ì´ ìˆì„ ë•Œ

**ëœë¤ ì„œì¹˜** : ë§¤ê°œë³€ìˆ˜ë¥¼ ìƒ˜í”Œë§í•  ìˆ˜ ìˆëŠ” í™•ë¥  ë¶„í¬ ê°ì²´ ì „ë‹¬
```python
from scipy.stats import uniform, randint 
params = {'min_impurity_decrease': uniform(0.0001, 0.001), 'max_depth': randint(20, 50), 'min_samples_split': randint(2, 25), 'min_samples_leaf': randint(1, 25),}

from sklearn.model_selection import RandomizedSearchCV
gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, n_iter=100, n_jobs=-1, random_state=42)
gs.fit(train_input, train_target)
```
- `uniform` : ì‹¤ìˆ«ê°’ ë½‘ìŒ
- `randint` : ì •ìˆ«ê°’ ë½‘ìŒ
## cf
```python
df.describe()
```
- ì‹œê°í™”ê°€ ì•„ë‹ˆë¼ describe ë¥¼ í™œìš©í•´ì„œ ìŠ¤ì¼€ì¼ í™•ì¸í•˜ê³  scaler ì‚¬ìš© ì—¬ë¶€ë¥¼ ê²°ì •í•´ë„ ë¨

```python
data = df.[['í–‰1', 'í–‰2', 'í–‰3', ...]].to_numpy()
target = df['íƒ€ê²Ÿë³€ìˆ˜'].to_numpy()
```
- Scikit-learn ê°™ì€ ML ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì´ NumPy ë°°ì—´ì„ ì…ë ¥ë°›ë„ë¡ ì„¤ê³„ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— numpy ë°°ì—´ë¡œ ë³€ê²½ å¿…
```python
random state = 00
```
- random state ìˆ«ìê°€ ê°™ì„ ê²½ìš° ë™ì¼í•œ ëœë¤ ë°ì´í„°ë¡œ í›ˆë ¨
- ì‹¤ì „ì—ì„œëŠ” í•„ìš”í•˜ì§€ ì•Šì§€ë§Œ, ì—°ìŠµ ë˜ëŠ” ì½”ë“œ ê³µìœ  ì‹œì— ê°™ì€ ìˆ«ìë¡œ í•˜ë©´ ë™ì¼í•œ ì ìˆ˜ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ

`scipy(ì‹¸ì´íŒŒì´) ë¼ì´ë¸ŒëŸ¬ë¦¬` : ì ë¶„, ë³´ê°„, ì„ í˜•ëŒ€ìˆ˜, í™•ë¥  ë“±ì„ í¬í•¨í•œ ìˆ˜ì¹˜ ê³„ì‚° ì „ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬(ì‹¸ì´í‚·ëŸ°ì´ ë„˜íŒŒì´ì™€ ì‹¸ì´íŒŒì´ ê¸°ëŠ¥ì„ ë§ì´ ì‚¬ìš©í•¨)

```python
from scipy.stats import uniform, randint
rgen = randint(0, 10)
np.unique(rgen.rvs(1000), return_counts=True)
```
- ì •ìˆ˜ 10ê°œì”© ë¬¶ì—¬ìˆëŠ” ë°°ì—´ 1000ê°œë¥¼ ë½‘ìŒ
- `randint` ìë¦¬ì— `uniform` ë„£ìœ¼ë©´ ì‹¤ìˆ˜ 10ê°œì”© ë¬¶ì—¬ìˆëŠ ë°°ì—´ 1000ê°œ ë½‘ìŒ